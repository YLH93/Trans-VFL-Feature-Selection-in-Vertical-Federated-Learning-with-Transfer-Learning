{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c91685-1554-42c3-9151-8cc455b745a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa023-f49f-491c-a6a1-610813bb9ec9",
   "metadata": {},
   "source": [
    "## Configuration & Simulation Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d784676-fa50-41eb-b01e-0396025b6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Configuration & Hyperparameters\n",
    "# ==========================================\n",
    "NUM_SITES = 10                  # \n",
    "NUM_PATIENTS = 200              # \n",
    "TOTAL_GENES = 5000              # \n",
    "GENES_PER_PATHWAY = 20          # Derived: 5000 genes / 250 pathways\n",
    "NUM_PATHWAYS = 250              # \n",
    "TRUE_PATHWAYS = 25              # (Implies 500 significant genes)\n",
    "\n",
    "# Hyperparameters for Stage 3\n",
    "LAMBDA_VAL = 0.08               # Slightly higher due to high noise (90% noise)\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad269413-bb78-4e77-8bdf-9bdb5cc0d3a6",
   "metadata": {},
   "source": [
    "## Data Generation (Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35106c4-dbe5-4c00-b474-27fe48aafc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Helper: Synthetic Data Generation\n",
    "# ==========================================\n",
    "def generate_genomic_site_data(n_samples):\n",
    "    \"\"\"\n",
    "    Simulates the output of the 'Frozen Base' (f_base).\n",
    "    The base has already processed raw genes into 'Pathway Features'.\n",
    "    \"\"\"\n",
    "    # We generate the 250 Pathway Features directly.\n",
    "    # First 25 are Signal, Next 225 are Noise.\n",
    "    \n",
    "    # 1. Generate Latent Pathway Activities\n",
    "    # Signal Pathways: High variance, correlated with Outcome\n",
    "    X_signal = torch.randn(n_samples, TRUE_PATHWAYS) * 2.0 \n",
    "    \n",
    "    # Noise Pathways: Standard normal, no correlation to Outcome\n",
    "    X_noise = torch.randn(n_samples, NUM_PATHWAYS - TRUE_PATHWAYS)\n",
    "    \n",
    "    # Combine to form the \"Learned Features\" z_m from the frozen base\n",
    "    X_pathways = torch.cat([X_signal, X_noise], dim=1)\n",
    "    \n",
    "    # 2. Generate Outcome (Survival/Binary)\n",
    "    # Only dependent on the first 25 pathways \n",
    "    # Simple linear relationship for simulation\n",
    "    true_weights = torch.randn(TRUE_PATHWAYS, 1)\n",
    "    logits = X_signal @ true_weights\n",
    "    y_prob = torch.sigmoid(logits)\n",
    "    y = (y_prob > 0.5).float()\n",
    "    \n",
    "    return X_pathways, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f055b-01f7-433a-9126-37bc2fbbca0d",
   "metadata": {},
   "source": [
    "## Trans-VFL Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5770ed-9da0-4175-ad35-59dd2990811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Trans-VFL Model (Pathway Level)\n",
    "# ==========================================\n",
    "class GeneSelectionModel(nn.Module):\n",
    "    def __init__(self, num_pathways, d_embed=16):\n",
    "        super(GeneSelectionModel, self).__init__()\n",
    "        \n",
    "        # Selection Layer: Takes 250 Pathways -> Filters them\n",
    "        # We use a diagonal weight matrix or element-wise scaling to select pathways\n",
    "        # Shape: [250] learnable weights (one per pathway)\n",
    "        self.selection_weights = nn.Parameter(torch.ones(num_pathways))\n",
    "        \n",
    "        # Embedding Head: Transforms selected pathways to shared embedding\n",
    "        self.embedding_head = nn.Linear(num_pathways, d_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply selection weights (element-wise multiplication)\n",
    "        # equivalent to weighting the entire \"group\" (pathway)\n",
    "        selected_features = x * self.selection_weights\n",
    "        \n",
    "        # Forward to embedding head\n",
    "        embedding = self.embedding_head(selected_features)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4c12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Stage 3 Algorithm: Distillation + Lasso\n",
    "# ==========================================\n",
    "def run_stage_3_genomics(site_id, X, initial_model):\n",
    "    print(f\"Site {site_id}: optimizing genomic features...\")\n",
    "    \n",
    "    # Student Model (Active)\n",
    "    student_model = GeneSelectionModel(NUM_PATHWAYS)\n",
    "    student_model.load_state_dict(initial_model.state_dict())\n",
    "    \n",
    "    # Teacher Model (Frozen Target from Stage 1)\n",
    "    initial_model.eval()\n",
    "    \n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=0.005)\n",
    "    \n",
    "    # Optimization Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Passes\n",
    "        with torch.no_grad():\n",
    "            target_embed = initial_model(X)\n",
    "        \n",
    "        student_embed = student_model(X)\n",
    "        \n",
    "        # Loss 1: Distillation (Match the pre-trained embedding) \n",
    "        mse_loss = nn.MSELoss()(student_embed, target_embed)\n",
    "        \n",
    "        # Loss 2: Group Lasso (L2,1) on Selection Weights\n",
    "        # Since we used a scaling vector for pathways, L1 norm of this vector \n",
    "        # acts as Group Lasso (selecting the whole pathway).\n",
    "        lasso_penalty = torch.norm(student_model.selection_weights, p=1)\n",
    "        \n",
    "        # Total Loss \n",
    "        loss = mse_loss + (LAMBDA_VAL * lasso_penalty)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Soft Thresholding (Proximal Operator)\n",
    "        # Forces small weights to exactly zero\n",
    "        with torch.no_grad():\n",
    "            mask = torch.abs(student_model.selection_weights) > 0.005\n",
    "            student_model.selection_weights.data *= mask.float()\n",
    "\n",
    "    # Evaluation\n",
    "    final_weights = student_model.selection_weights.data.abs()\n",
    "    \n",
    "    # Count Pathways (Indices 0-24 are True, 25-249 are Noise)\n",
    "    kept_indices = torch.where(final_weights > 0.01)[0]\n",
    "    \n",
    "    tp_pathways = sum(1 for idx in kept_indices if idx < TRUE_PATHWAYS)\n",
    "    fp_pathways = sum(1 for idx in kept_indices if idx >= TRUE_PATHWAYS)\n",
    "    \n",
    "    return tp_pathways, fp_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dba2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Simulation 3.2] Genomic Data: 200 Patients, 10 Sites\n",
      "Total Genes: 5000 | Mapped to Pathways: 250\n",
      "Ground Truth: 25 Significant Pathways (500 Genes)\n",
      "============================================================\n",
      "Site 0: optimizing genomic features...\n",
      "   > Site 0 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 1: optimizing genomic features...\n",
      "   > Site 1 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 2: optimizing genomic features...\n",
      "   > Site 2 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 3: optimizing genomic features...\n",
      "   > Site 3 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 4: optimizing genomic features...\n",
      "   > Site 4 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 5: optimizing genomic features...\n",
      "   > Site 5 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 6: optimizing genomic features...\n",
      "   > Site 6 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 7: optimizing genomic features...\n",
      "   > Site 7 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 8: optimizing genomic features...\n",
      "   > Site 8 Result: Kept 500 Genes. (TP: 500/500)\n",
      "Site 9: optimizing genomic features...\n",
      "   > Site 9 Result: Kept 500 Genes. (TP: 500/500)\n",
      "============================================================\n",
      "FINAL RESULTS (Averaged across 10 sites):\n",
      "Total Genes Selected: 500 / 5000\n",
      "True Positive Genes:  500 / 500 (Target: 500)\n",
      "False Positive Genes: 0 / 4500\n",
      "============================================================\n",
      "Reference (Table 2): Trans-VFL Selected 475/5000 [cite: 245]\n",
      "Reference (Table 2): Group Lasso Selected 525/5000 [cite: 245]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Main Simulation\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"[Simulation 3.2] Genomic Data: {NUM_PATIENTS} Patients, {NUM_SITES} Sites\")\n",
    "    print(f\"Total Genes: {TOTAL_GENES} | Mapped to Pathways: {NUM_PATHWAYS}\")\n",
    "    print(f\"Ground Truth: {TRUE_PATHWAYS} Significant Pathways ({TRUE_PATHWAYS*GENES_PER_PATHWAY} Genes)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_tp_genes = 0\n",
    "    total_fp_genes = 0\n",
    "    \n",
    "    samples_per_site = NUM_PATIENTS // NUM_SITES # Very small! (20 per site)\n",
    "    \n",
    "    for site in range(NUM_SITES):\n",
    "        # 1. Generate Data (Output of frozen base)\n",
    "        X_site, y_site = generate_genomic_site_data(samples_per_site)\n",
    "        \n",
    "        # 2. Simulate Pre-trained Model (Teacher)\n",
    "        # Teacher knows signal is in first 25, but has noise in the rest\n",
    "        initial_model = GeneSelectionModel(NUM_PATHWAYS)\n",
    "        with torch.no_grad():\n",
    "            # Strong signal weights\n",
    "            initial_model.selection_weights[:TRUE_PATHWAYS].uniform_(0.8, 1.2)\n",
    "            # Weak noise weights (Stage 1 didn't prune them yet)\n",
    "            initial_model.selection_weights[TRUE_PATHWAYS:].uniform_(0.0, 0.2)\n",
    "            \n",
    "        # 3. Run Trans-VFL Stage 3\n",
    "        tp_path, fp_path = run_stage_3_genomics(site, X_site, initial_model)\n",
    "        \n",
    "        # Convert Pathways to Genes for reporting (as per Table 2)\n",
    "        # 1 Pathway = 20 Genes\n",
    "        tp_genes = tp_path * GENES_PER_PATHWAY\n",
    "        fp_genes = fp_path * GENES_PER_PATHWAY\n",
    "        \n",
    "        total_tp_genes += tp_genes\n",
    "        total_fp_genes += fp_genes\n",
    "        \n",
    "        print(f\"   > Site {site} Result: Kept {tp_genes + fp_genes} Genes. (TP: {tp_genes}/{TRUE_PATHWAYS*GENES_PER_PATHWAY})\")\n",
    "\n",
    "    avg_tp = total_tp_genes / NUM_SITES\n",
    "    avg_total_selected = (total_tp_genes + total_fp_genes) / NUM_SITES\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"FINAL RESULTS (Averaged across {NUM_SITES} sites):\")\n",
    "    print(f\"Total Genes Selected: {int(avg_total_selected)} / {TOTAL_GENES}\")\n",
    "    print(f\"True Positive Genes:  {int(avg_tp)} / {TRUE_PATHWAYS*GENES_PER_PATHWAY} (Target: 500)\")\n",
    "    print(f\"False Positive Genes: {int(avg_total_selected - avg_tp)} / {TOTAL_GENES - (TRUE_PATHWAYS*GENES_PER_PATHWAY)}\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-vs1]",
   "language": "python",
   "name": "conda-env-anaconda3-vs1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
